{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "from itertools import repeat\n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into data_loader form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the way Pytorch reads data, class like a container\n",
    "which takes data then returns data and labels\n",
    "\"\"\"\n",
    "class My_dataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.data_info = pd.read_csv(csv_path,header=None)\n",
    "        self.data = np.asarray(self.data_info.iloc[:,1:7], dtype=np.float64)\n",
    "        self.label = np.asarray(self.data_info.iloc[:,7], dtype=np.float64)\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        single_row = self.data[index]\n",
    "        row = torch.FloatTensor(single_row)\n",
    "        target = torch.from_numpy(np.array(self.label[index]) )\n",
    "        return (row, target)\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = My_dataset('new_data/train_set.csv')\n",
    "train_data = DataLoader(dataset=new_data,\n",
    "                       batch_size=10,\n",
    "                       shuffle=False)\n",
    "\n",
    "new_data = My_dataset('new_data/val_set.csv')\n",
    "val_data = DataLoader(dataset=new_data,\n",
    "                       batch_size=5,\n",
    "                       shuffle=False)\n",
    "\n",
    "new_data = My_dataset('new_data/test_set.csv')\n",
    "test_data = DataLoader(dataset=new_data,\n",
    "                       batch_size=5,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0956,  0.1021,  0.0827,  0.0933,  0.0925,  0.4524],\n",
      "        [ 0.1168,  0.0979,  0.0915,  0.1298,  0.0949,  0.3205],\n",
      "        [ 0.0583,  0.1700,  0.0891,  0.1987,  0.1294,  0.3986],\n",
      "        [ 0.2214,  0.2192,  0.2466,  0.2242,  0.2337,  0.2602],\n",
      "        [ 0.1873,  0.1804,  0.1630,  0.1296,  0.1721,  0.4058]])\n",
      "tensor([ 0.1276,  0.1953,  0.2204,  0.1274,  0.1625], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data,label in test_data:\n",
    "    print data\n",
    "    print label\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=64, hidden_size2=128, num_securities=1, dropout=0.2, n_layers=4, T=10):\n",
    "\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=num_securities,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc1.weight.data.normal_()\n",
    "        self.fc3 = nn.Linear(self.hidden_size, 10)\n",
    "        self.fc2 = nn.Linear(10, num_securities)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.size()[1]\n",
    "        seq_length = x.size()[0]\n",
    "        x = x.view(seq_length, batch_size, -1)  # just to be sure of the dimensions\n",
    "        # Initial cell states\n",
    "        h0 = Variable(torch.zeros(self.rnn.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        c0 = Variable(torch.zeros(self.rnn.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        outputs, (ht, ct) = self.rnn(x, (h0, c0))\n",
    "        out = outputs[-1]  # last prediction\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-115-01564de6f560>\", line 15, in __getitem__\n    target = torch.FloatTensor(self.label[index])\nTypeError: new(): data must be a sequence (got numpy.float64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-9e1e7915a88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m#target.unsqueeze_(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-115-01564de6f560>\", line 15, in __getitem__\n    target = torch.FloatTensor(self.label[index])\nTypeError: new(): data must be a sequence (got numpy.float64)\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "max_epochs = 100\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 128\n",
    "T = 10\n",
    "display_step = 50\n",
    "\n",
    "\n",
    "#fn_base = \"lstm_nstocks_\" + str(n_stocks) + \"_epochs_\" + str(max_epochs) + \"_T_\" + str(T)\n",
    "\n",
    "# training data\n",
    "\n",
    "'''\n",
    "train_loader = DataLoader(X_train,y_train,\n",
    "             batch_size=batch_size,\n",
    "             shuffle=False,\n",
    "             num_workers=4,\n",
    "             pin_memory=True  # CUDA only\n",
    "            )'''\n",
    "\n",
    "new_data = My_dataset('new_data/train_set.csv')\n",
    "train_loader = DataLoader(dataset=new_data,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=False,\n",
    "                       num_workers=4,\n",
    "                       pin_memory=True  # CUDA only\n",
    "                       )\n",
    "\n",
    "model = LSTM(hidden_size=n_hidden1, hidden_size2=n_hidden2, num_securities=1, dropout=0.2, n_layers=4, T=T).cuda()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=0.0)  # n\n",
    "scheduler_model = lr_scheduler.StepLR(optimizer, step_size=1, gamma=1.0)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.MSELoss(size_average=True).cuda()\n",
    "# Store successive losses\n",
    "losses = []\n",
    "it = 0\n",
    "for i in range(max_epochs):\n",
    "    loss_ = 0.\n",
    "    # Store current predictions\n",
    "    predicted = []\n",
    "    gt = []\n",
    "    for data, target in train_loader:\n",
    "        #target.unsqueeze_(0)\n",
    "        print target\n",
    "        data = Variable(data.permute(1, 0)).contiguous()\n",
    "        target = Variable(target.unsqueeze_(0))\n",
    "        #print target\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        if target.data.size()[1] == batch_size:\n",
    "                # Set optimizer gradient to 0\n",
    "                optimizer.zero_grad()\n",
    "                # Compute predictions\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss_ += loss.data[0]\n",
    "                # Backpropagation\n",
    "                loss.backward()\n",
    "                # Gradient descent step\n",
    "                optimizer.step()\n",
    "                for k in range(batch_size):\n",
    "                    predicted.append(output.data[k, 0])\n",
    "                    gt.append(target.data[:, k, 0])\n",
    "        it += 1\n",
    "        break\n",
    "        \n",
    "    print(\"Epoch = \", i)\n",
    "    print(\"Loss = \", loss_)\n",
    "    losses.append(loss_)\n",
    "    scheduler_model.step()\n",
    "        # Visual check\n",
    "        # Plot current predictions\n",
    "    break\n",
    "    if i % display_step == 0:\n",
    "        predicted = np.array(predicted).reshape(-1, 1)\n",
    "        gt = np.array(gt).reshape(-1, 1)\n",
    "        x = np.array(range(predicted.shape[0]))\n",
    "        plt.figure()\n",
    "        plt.plot(x, predicted[:, 0], label=\"predictions\")\n",
    "        plt.plot(x, gt[:, 0], label=\"true\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "           \n",
    "'''            \n",
    "#####TEST#####\n",
    "predictions = np.zeros((len(train_loader.dataset.chunks), n_stocks))\n",
    "ground_tr = np.zeros((len(train_loader.dataset.chunks), n_stocks))\n",
    "batch_size_pred = 4\n",
    "\n",
    "test_loader = DataLoader(X_test,\n",
    "                             batch_size=batch_size_pred,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4,\n",
    "                             pin_memory=True  # CUDA only\n",
    "                             )\n",
    "predictions = [[] for i in repeat(None, len(symbols))]\n",
    "gts = [[] for i in repeat(None, len(symbols))]\n",
    "k = 0\n",
    "    # Predictions\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data.permute(1, 0, 2)).contiguous()\n",
    "        target = Variable(target.unsqueeze_(1))\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        if target.data.size()[0] == batch_size_pred:\n",
    "            output = model(data)\n",
    "            for k in range(batch_size_pred):\n",
    "                s = 0\n",
    "                for stock in symbols:\n",
    "                    predictions[s].append(output.data[k, s])\n",
    "                    gts[s].append(target.data[k, 0, s])\n",
    "                    s += 1\n",
    "            k += 1\n",
    "            \n",
    "if len(symbols) == 1:\n",
    "        pred = dtest.scaler.inverse_transform(np.array(predictions[0]).reshape((len(predictions[0]), 1)))\n",
    "        gt = dtest.scaler.inverse_transform(np.array(gts[0]).reshape(len(gts[0]), 1))\n",
    "if len(symbols) >= 2:\n",
    "        p = np.array(predictions)\n",
    "        pred = dtest.scaler.inverse_transform(np.array(predictions).transpose())\n",
    "        gt = dtest.scaler.inverse_transform(np.array(gts).transpose())\n",
    "# Plots for all stocks in list of symbols\n",
    "x = np.array(range(pred.shape[0]))\n",
    "x = [np.datetime64(start_date) + np.timedelta64(x, 'D') for x in range(0, pred.shape[0])]\n",
    "x = np.array(x)\n",
    "months = MonthLocator(range(1, 10), bymonthday=1, interval=1)\n",
    "monthsFmt = DateFormatter(\"%b '%y\")\n",
    "s = 0\n",
    "for stock in symbols:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "        plt.plot(x, pred[:, s], label=\"predictions\", color=cm.Blues(300))\n",
    "        plt.plot(x, gt[:, s], label=\"true\", color=cm.Blues(100))\n",
    "        ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "        ax.xaxis.set_major_locator(months)\n",
    "        ax.xaxis.set_major_formatter(monthsFmt)\n",
    "        plt.title(stock)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Stock Price\")\n",
    "        plt.legend()\n",
    "        fig.autofmt_xdate()\n",
    "        plt.savefig(stock + \"_\" + fn_base + '.png')\n",
    "        plt.show()\n",
    "        s += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.8922e+18, -1.5403e+18,  3.5415e+18,  1.4536e+19, -1.0349e+19,\n",
       "         -1.0342e+19, -2.8257e+18, -6.7951e+18,  6.3535e+18, -5.2782e+18,\n",
       "          1.0625e+18, -1.1546e+18, -2.4834e+18, -1.0105e+19,  4.7303e+17,\n",
       "         -6.3568e+18, -1.0486e+18,  1.6319e+18,  4.1486e+18,  6.5165e+18,\n",
       "          2.6757e+17,  4.3110e+18,  6.9138e+18, -3.4509e+18,  2.1217e+18,\n",
       "         -1.1719e+19, -5.8876e+18,  4.9299e+17,  7.6399e+17,  4.8994e+18,\n",
       "         -4.5325e+18,  1.3813e+18, -3.2900e+18, -9.3152e+18,  1.0677e+19,\n",
       "          7.4735e+18, -1.9398e+17, -9.5256e+17, -2.2828e+18,  1.6390e+18,\n",
       "         -6.9768e+18, -1.1001e+18, -1.6823e+18, -1.4505e+19,  4.5135e+18,\n",
       "          5.1097e+18,  9.5075e+17,  1.7511e+18, -2.3556e+18, -4.2066e+18,\n",
       "         -9.4787e+18,  9.3782e+18, -2.0038e+18, -5.0958e+18, -6.8008e+18,\n",
       "          3.0166e+17,  4.1820e+18,  2.3359e+17, -1.3438e+19,  1.0394e+18,\n",
       "          2.4459e+18, -1.6044e+18, -8.8111e+17, -3.3547e+18, -1.3995e+18,\n",
       "         -4.7318e+17,  4.3216e+18,  2.1572e+18,  2.6049e+18,  2.1766e+18,\n",
       "         -4.5915e+18,  7.6029e+18, -4.9128e+18,  8.8059e+16, -1.1282e+19,\n",
       "          5.0268e+18, -6.5862e+18,  2.5709e+18,  9.4356e+18, -3.7676e+18,\n",
       "          2.3289e+18, -6.1775e+18,  7.9564e+18, -8.0905e+18,  7.6087e+18,\n",
       "          3.4964e+18, -6.6827e+18,  1.3112e+18,  1.1699e+19, -3.0813e+18,\n",
       "          1.4802e+19,  1.3787e+19,  1.3809e+18,  6.5727e+17, -4.9319e+18,\n",
       "         -8.0221e+18, -8.4040e+18, -5.7725e+17,  4.1908e+18, -1.4893e+19,\n",
       "         -1.9300e+19, -5.6665e+16, -1.4521e+17,  1.2583e+19, -6.0573e+18,\n",
       "         -2.0850e+18, -8.8848e+18,  2.7795e+18, -7.1892e+17, -5.8314e+18,\n",
       "          1.3381e+18,  3.5586e+18, -2.7363e+18, -1.6438e+18,  1.1099e+18,\n",
       "          1.1434e+18,  8.0892e+18, -1.4442e+18, -5.9589e+18, -5.3689e+18,\n",
       "          2.4979e+18,  4.8096e+18,  1.6506e+18,  1.2935e+19, -2.0859e+19,\n",
       "         -8.5518e+18, -1.4316e+19,  1.7165e+18],\n",
       "        [-1.2349e+19,  3.5329e+18,  7.1639e+18, -1.2027e+19,  3.1525e+18,\n",
       "         -1.1848e+19,  7.2377e+18, -4.5204e+18,  4.9568e+18, -1.3013e+19,\n",
       "          7.2444e+18, -2.3241e+18,  1.2446e+19,  1.3217e+18, -2.0415e+17,\n",
       "          2.3569e+18, -6.9577e+18, -3.9011e+18,  1.9599e+19, -1.9368e+18,\n",
       "          2.7605e+18, -2.0898e+18, -7.4574e+18, -1.0659e+19, -8.1017e+18,\n",
       "         -1.6498e+19,  2.9136e+18, -3.9618e+18, -9.0332e+18, -9.5969e+18,\n",
       "          2.5624e+18, -3.9103e+18, -1.3276e+19, -2.6118e+17,  6.2755e+18,\n",
       "          2.1026e+19,  3.8868e+18,  3.2939e+18, -2.7145e+19, -1.0690e+19,\n",
       "         -2.3061e+18,  1.4920e+19,  2.0001e+18, -2.9354e+18,  5.3941e+17,\n",
       "         -4.2540e+18,  7.0464e+18, -3.1938e+18,  5.9145e+17, -1.0349e+19,\n",
       "          4.9532e+18,  1.2283e+19,  1.0986e+19, -4.3451e+18, -8.7455e+17,\n",
       "          1.7339e+19,  1.3067e+19, -3.9580e+18, -1.1828e+19,  1.5998e+19,\n",
       "         -6.4903e+18, -1.6220e+19, -1.3339e+19, -6.3655e+18,  2.3241e+18,\n",
       "          7.5038e+18,  1.3764e+19,  1.0026e+19,  1.7380e+18,  4.2977e+18,\n",
       "         -2.2543e+18,  7.6631e+18,  1.2850e+18, -2.9040e+18, -6.4146e+18,\n",
       "          2.3780e+18, -8.9591e+18,  1.5159e+19,  8.0020e+18,  1.3705e+18,\n",
       "          5.9358e+18, -7.5625e+18,  8.1329e+18, -1.3015e+19,  1.5750e+19,\n",
       "          1.4560e+19, -6.3708e+18,  6.0766e+18,  1.2711e+19, -8.5308e+18,\n",
       "          1.3427e+18, -1.4685e+18,  1.2967e+18,  6.9864e+18, -9.3042e+18,\n",
       "         -3.0465e+18,  1.4605e+19, -1.9748e+17,  9.2721e+17, -1.6989e+17,\n",
       "         -1.2222e+19,  1.5060e+19, -1.9403e+18, -6.7078e+16,  1.3413e+19,\n",
       "         -2.1034e+19,  5.7572e+18,  8.6887e+18,  1.0254e+19,  4.3389e+18,\n",
       "         -1.4448e+19,  5.3971e+18, -1.0320e+19, -1.5649e+19, -1.0086e+19,\n",
       "          3.0840e+17,  6.8911e+18, -2.2709e+18, -2.7341e+18, -2.2395e+18,\n",
       "         -4.7639e+18, -1.0413e+19,  6.2942e+18,  3.0858e+18, -2.0133e+18,\n",
       "         -2.3539e+18, -1.3625e+18, -6.4171e+18]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(128, 128)\n",
    "fc(torch.FloatTensor(16,2,128)[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([16,28,14])[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
